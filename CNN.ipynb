{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(X, Y), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Class labels for CIFAR-10\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Display a few images from the dataset\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X[i])\n",
    "    plt.title(class_labels[Y[i][0]])\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = X.reshape(-1, 32*32*3).astype(float)\n",
    "X_scaled = scaler.fit_transform(X_scaled).reshape(-1, 32, 32, 3)\n",
    "X_test_scaled = X_test.reshape(-1, 32*32*3).astype(float)\n",
    "X_test_scaled = scaler.transform(X_test_scaled).reshape(-1, 32, 32, 3)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_temp, X_test_scaled, Y_temp, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_val, Y_val))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "conf_matrix = confusion_matrix(Y_test, y_pred_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(Y_test, y_pred_labels, average='weighted')\n",
    "recall = recall_score(Y_test, y_pred_labels, average='weighted')\n",
    "\n",
    "# Output accuracy, precision, and recall\n",
    "print(f\"Train accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"Training model with learning rate: {lr}\")\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_val, Y_val), verbose=1)\n",
    "    \n",
    "    train_losses.append(history.history['loss'])\n",
    "    val_losses.append(history.history['val_loss'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    plt.plot(train_losses[i], label=f'Training Loss (LR={lr})')\n",
    "    plt.plot(val_losses[i], label=f'Validation Loss (LR={lr})')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss for Different Learning Rates')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
